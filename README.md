# TP2 - POS Tagging com BERT

Trabalho PrÃ¡tico 2 da disciplina de Processamento de Linguagem Natural.  
**Aluno**: Caio Santana Trigueiro | **MatrÃ­cula**: 2022043310

## ğŸ“ DescriÃ§Ã£o

ImplementaÃ§Ã£o e avaliaÃ§Ã£o de um modelo de **POS Tagging** (Part-of-Speech Tagging) utilizando BERT. O objetivo Ã© classificar a classe gramatical de palavras em textos e **analisar a precisÃ£o do modelo em cada uma das 48 classes gramaticais** do Penn Treebank.

## ğŸ“Š Dataset

- **Fonte:** [batterydata/pos_tagging](https://huggingface.co/datasets/batterydata/pos_tagging)
- **Penn Treebank format**
- **48 classes gramaticais** (POS tags)
- **Train:** 13,054 sentenÃ§as (321,815 tokens)
- **Test:** 1,451 sentenÃ§as (37,965 tokens)
- **Validation:** 10% do train (criado automaticamente)

## ğŸš€ Tecnologias

- Python 3.12+
- PyTorch 2.9+
- Transformers 4.57+ (Hugging Face)
- BERT (bert-base-uncased)
- Datasets (Hugging Face)
- Evaluate (seqeval)
- Scikit-learn, Pandas, Matplotlib, Seaborn
- Jupyter Notebook

## ğŸ“¦ Como Usar

### OpÃ§Ã£o 1: Google Colab (Recomendado) â­

1. Acesse [Google Colab](https://colab.research.google.com/)
2. FaÃ§a upload do notebook `TP2_POS_Tagging_Colab.ipynb`
3. Execute cÃ©lula por cÃ©lula ou "Runtime > Run all"
4. Aguarde ~8-10 minutos (execuÃ§Ã£o automÃ¡tica com GPU)

### OpÃ§Ã£o 2: InstalaÃ§Ã£o Local

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/caio-santt/tp2-nlp-pos-tagging.git
cd tp2-nlp-pos-tagging
```

2. Crie e ative o ambiente virtual:
```bash
python3 -m venv tp2-env
source tp2-env/bin/activate  # Linux/Mac
# ou
tp2-env\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Inicie o Jupyter:
```bash
jupyter notebook
```

## ğŸ““ Notebook

### â˜ï¸ RecomendaÃ§Ã£o: Use o Google Colab!

O notebook foi desenvolvido para execuÃ§Ã£o no **Google Colab** (GPU gratuita):
- Upload do arquivo `.ipynb` no Colab
- ExecuÃ§Ã£o automÃ¡tica em ~8-10 minutos
- Todas as dependÃªncias instaladas automaticamente
- Sem necessidade de configuraÃ§Ã£o local

**Link do Colab:** [Open in Colab](https://colab.research.google.com/)

### ğŸ“ ConteÃºdo do Notebook

O notebook principal `TP2_POS_Tagging_Colab.ipynb` estÃ¡ **completo** e contÃ©m:

1. **ConfiguraÃ§Ã£o Inicial** - Imports e setup
2. **ExploraÃ§Ã£o dos Dados** - AnÃ¡lise do dataset e 48 classes
3. **Preprocessamento** - TokenizaÃ§Ã£o BERT com alinhamento de labels
4. **Modelagem** - Fine-tuning do BERT (3 Ã©pocas)
5. **AvaliaÃ§Ã£o** - MÃ©tricas no conjunto de teste
6. **AnÃ¡lise Detalhada por Classe** â­ (Requisito Principal)
   - Precision, Recall, F1 para cada uma das 48 classes
   - Top 10 e Bottom 10 classes
   - GrÃ¡fico de F1 por classe
   - Matriz de confusÃ£o (top 15)
   - Classification report completo
7. **Exemplos** - PrediÃ§Ãµes em sentenÃ§as reais
8. **ConclusÃµes** - AnÃ¡lise de pontos fortes, fracos e melhorias

## ğŸ¯ Objetivos

âœ… Implementar modelo de POS tagging usando BERT  
âœ… TokenizaÃ§Ã£o com alinhamento de subword tokens  
âœ… Avaliar mÃ©tricas globais (accuracy, F1, precision, recall)  
âœ… **Analisar precisÃ£o por classe gramatical** (48 classes)  
âœ… Identificar classes com melhor e pior desempenho  
âœ… Visualizar resultados (grÃ¡ficos + matriz de confusÃ£o)  
âœ… Salvar modelo treinado e resultados em CSV  

## ğŸ“ˆ Resultados Esperados

O modelo deve alcanÃ§ar:
- **Accuracy > 95%**
- **F1 Score mÃ©dio > 95%**
- **Alta precisÃ£o** em classes frequentes: NN, IN, DT, NNP, JJ
- **Desafios** em classes raras: SYM, LS, UH (baixo support)

## â±ï¸ Tempo de ExecuÃ§Ã£o

- **Google Colab (GPU T4)**: ~8-10 minutos âš¡
- **GPU local (CUDA)**: ~15-20 minutos
- **CPU local**: ~2-3 horas ğŸ¢

## ğŸ“ Arquivos Gerados

ApÃ³s execuÃ§Ã£o do notebook:
- `pos_tagging_results_by_class.csv` - MÃ©tricas detalhadas por classe
- `modelo_bert_pos_tagging/` - Modelo BERT treinado
- `results/` - Checkpoints de treinamento
- `logs/` - Logs do TensorBoard

## ğŸ“š ReferÃªncias

- Devlin, J., et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers)
- [Dataset batterydata/pos_tagging](https://huggingface.co/datasets/batterydata/pos_tagging)

## ğŸ‘¤ Autor

**Caio Santana Trigueiro**  
MatrÃ­cula: 2022043310  
Curso: CiÃªncia da ComputaÃ§Ã£o  
Disciplina: Processamento de Linguagem Natural

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins acadÃªmicos.
